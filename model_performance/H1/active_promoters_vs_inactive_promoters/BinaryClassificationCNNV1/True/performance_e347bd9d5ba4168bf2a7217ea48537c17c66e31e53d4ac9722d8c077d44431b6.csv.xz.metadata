{
    "creation_time": 1639676102.3206086,
    "creation_time_human": "2021-12-16 17:35:02",
    "time_delta": 192.07032990455627,
    "time_delta_human": "3 minutes and 12 seconds",
    "file_dump_time": 0.012704133987426758,
    "file_dump_time_human": "0 seconds",
    "file_dump_size": 916,
    "file_dump_size_human": "916 Bytes",
    "load_kwargs": {},
    "dump_kwargs": {},
    "function_name": "train_model",
    "function_file": "<ipython-input-9-98b69b54245e>:3",
    "args_to_ignore": [
        "model",
        "training_sequence",
        "test_sequence"
    ],
    "source": "@Cache(\n    cache_path=[\n        \"/content/drive/MyDrive/Colab_Notebooks/Bioinformatica/Progetto/CNN/model_histories/{cell_line}/{task}/{model_name}/{use_feature_selection}/history_{_hash}.csv.xz\",\n        \"/content/drive/MyDrive/Colab_Notebooks/Bioinformatica/Progetto/CNN/model_performance/{cell_line}/{task}/{model_name}/{use_feature_selection}/performance_{_hash}.csv.xz\",\n    ],\n    args_to_ignore=[\n        \"model\", \"training_sequence\", \"test_sequence\"\n    ]\n)\ndef train_model(\n    model: Model,\n    model_name: str,\n    task: str,\n    cell_line: str,\n    training_sequence: MixedSequence,\n    test_sequence: MixedSequence,\n    holdout_number: int,\n    use_feature_selection: bool,\n    start_time: time\n) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Returns training history and model evaluations.\n    \n    Parameters\n    ---------------------\n    model: Model,\n        The model to train.\n    model_name: str,\n        The model name.\n    task: str,\n        The name of the task.\n    cell_line: str,\n        Name of the considered cell line.\n    training_sequence: MixedSequence,\n        The training sequence.\n    test_sequence: MixedSequence,\n        The test sequence.\n    holdout_number: int,\n        The number of the current holdout.\n    use_feature_selection: bool,\n        Whether the model is trained using features that have\n        been selected with Boruta or not.\n\n    Returns\n    ----------------------\n    Tuple with training history dataframe and model evaluations dataframe.\n    \"\"\"\n    \n    history = pd.DataFrame(model.fit(\n        train_sequence,\n        validation_data=test_sequence,\n        epochs=1000,\n        verbose=False,\n        callbacks=[\n            EarlyStopping(\n                \"loss\",\n                min_delta=0.001,\n                patience=2,\n                mode=\"min\"\n            ),\n            #TqdmCallback(verbose=1)\n        ]\n    ).history)\n    \n    train_evaluation = dict(zip(model.metrics_names, model.evaluate(train_sequence, verbose=False)))\n    test_evaluation = dict(zip(model.metrics_names, model.evaluate(test_sequence, verbose=False)))\n    train_evaluation[\"run_type\"] = \"train\"\n    test_evaluation[\"run_type\"] = \"test\"\n    \n    for evaluation in (train_evaluation, test_evaluation):\n        evaluation[\"model_name\"] = model_name\n        evaluation[\"task\"] = task\n        evaluation[\"holdout_number\"] = holdout_number \n        evaluation[\"use_feature_selection\"] = use_feature_selection\n        evaluation[\"elapsed_time\"] = round(time.time() - start_time, 2)\n    \n    evaluations = pd.DataFrame([\n        train_evaluation,\n        test_evaluation\n    ])\n    \n    return history, evaluations\n",
    "backend_metadata": {
        "type": "pandas",
        "columns_types": {
            "loss": "float64",
            "accuracy": "float64",
            "recall": "float64",
            "precision": "float64",
            "AUROC": "float64",
            "AUPRC": "float64",
            "f1_score": "float64",
            "balanced_accuracy": "float64",
            "specificity": "float64",
            "miss_rate": "float64",
            "fall_out": "float64",
            "mcc": "float64",
            "true_positives_over_total": "float64",
            "false_positives_over_total": "float64",
            "true_negatives_over_total": "float64",
            "false_negatives_over_total": "float64",
            "negative_predictive_value": "float64",
            "false_discovery_rate": "float64",
            "false_omission_rate": "float64",
            "prevalence_threshold": "float64",
            "threat_score": "float64",
            "fowlkes_mallows_index": "float64",
            "informedness": "float64",
            "markedness": "float64",
            "positive_likelyhood_ratio": "float64",
            "negative_likelyhood_ratio": "float64",
            "DOR": "float64",
            "run_type": "str",
            "model_name": "str",
            "task": "str",
            "holdout_number": "int64",
            "use_feature_selection": "bool",
            "elapsed_time": "float64"
        },
        "index_type": "int64",
        "columns_names_type": "str"
    },
    "parameters": {
        "model_name": "BinaryClassificationCNNV1",
        "task": "active_promoters_vs_inactive_promoters",
        "cell_line": "H1",
        "holdout_number": 6,
        "use_feature_selection": true,
        "start_time": 1639675446.89307
    }
}